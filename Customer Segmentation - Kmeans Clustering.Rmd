##Clustering in R

#Read and explore the data

##Step1 : Reading and exploring thedataset

```{r}
data<-read.csv("cust.csv")

dim(data)
str(data)
names(data)
summary(data)
```
 
```{r}
colSums(is.na(data)) 
```

#Frequency distribution

```{r}
table(data$Channel)
table(data$Region)
```

#Subsetting Data to only Price ,Bedrooms,Squarefeet

```{r}
names(data)
sample<-data[,3:8]
dim(sample)
str(sample)
names(sample)
```

##Step2 : Scaling the data 
#(column  - mean(column))/sd(column)
#Repeat for all columns

```{r}
list<-names(sample)
scaled_data<-data.frame(rownum<-1:440)
```

*.*

```{r}
for(i in 1:length(list))
{
  
  x<-(sample[,i]-mean(sample[,i]))/(sd(sample[,i]))
  scaled_data<-cbind(scaled_data,x)
  names(scaled_data)[i+1]<-paste("scaled_",list[i])
  print(list[i])
  
}

head(scaled_data)
```

#Deleting column 1

```{r}
scaled_data<-scaled_data[,-1]
```

```{r}
sample<-cbind(sample,scaled_data)

names(sample)
head(sample)
```

##Step3 : kmeans algorithm 
#syntax : kmeans(scaled_data,k) ; where k refers to the number of clusters

```{r}
set.seed(200)
names(sample)
fit.km<-kmeans(sample[,7:12],3)
```

#No of observations in each cluster

```{r}
fit.km$size 
```

#Within sum of squares metric for each cluster

```{r}
fit.km$withinss
```

#The total sum of squares

```{r}
fit.km$totss 
```

#Total within-cluster sum of squares, i.e., sum(withinss)

```{r}
fit.km$tot.withinss 
```

#The between-cluster sum of squares, i.e. totss-tot.withinss

```{r}
fit.km$betweenss 
```

##Step4 : find the optimal number of clusters (k value) 

#Create a screeplot-plot of cluster's tot.withinss wrt number of clusters

```{r}
wss<-1:15
number<-1:15

for (i in 1:15)
  
{
  wss[i]<-kmeans(sample[,7:12],i)$tot.withinss
}

head(wss)
```

#Shortlised optimal number of clusters : between 7 and 9

#Better plot using ggplot2

```{r}
library(ggplot2)
data<-data.frame(wss,number)

p<-ggplot(data,aes(x=number,y=wss),color="red")
p+geom_point()+scale_x_continuous(breaks=seq(1,20,1))
```

##Step5a : Rerun the algorithm with k=9(optimal no)

#Build 9 cluster model

```{r}
set.seed(100)

head(fit.km$cluster)
length(fit.km$cluster)

fit.km<-kmeans(sample[,7:12],9)
```

##Merging the cluster output with original data

```{r}
head(fit.km$cluster)
sample$cluster9<-fit.km$cluster
```

##Step5b : Profile the clusters

```{r}
names(sample)
```

#Cluster wise Aggregates

```{r}
cmeans<-aggregate(sample[,1:6],by=list(sample$cluster),FUN=mean)
cmeans
dim(cmeans)
```

#Population Aggregates

```{r}
apply(sample[,1:6],2,mean)
apply(sample[,1:6],2,sd)

list1<-names(cmeans)
```

#Z score calculation
#z score =population_mean - group_mean /population_sd

```{r}
for(i in 1:length(list1))
{
y<-(cmeans[,i+1] - apply(sample[,1:6],2,mean)[i])/(apply(sample[,1:6],2,sd)[i])
cmeans<-cbind(cmeans,y)
names(cmeans)[i+7]<-paste("z",list1[i+1],sep="_")
print(list1[i+1])
}

cmeans
```

```{r}
cmeans<-cmeans[,-14]
names(cmeans)
```

```{r}
write.csv(cmeans, "cmeans.csv", row.names = F)
```

##Step6 : Visualise the clusters

In this step basically we're going to try and visualize the clusters.

#Plotting groups across two dimensions

```{r}
library(ggplot2)
data<-cbind(data,sample$cluster9)
names(data)[9] <- "cluster"
```

#For cluster9
#Milk Vs Grocery
#Annual spending of milk and grocery.

```{r}
p<-ggplot(data,aes(x=Milk,y=Grocery))
p+geom_point(aes(colour=as.factor(cluster))) #Customers spending on annual spending on milk seems to be increasing. 

```

#Across Region

I am basically trying to understand - does the spending on milk and grocery actually differ based on the region? And you can see that there 
are 3 regions here. 1, 2 and 3. Now the third region basically refers to other regions which have not been specified. And the first region 
and the second region seem to be a little bit more specific regions. Let me just give you a briefing of the 2 regions.

Region 1 refers to Lisbon and region 2 refers to Oporto and the third region, basically region 3 or the number 3 refers to other regions.

```{r}
p+geom_point(aes(colour=as.factor(cluster)))+
  facet_grid(Region~.)
```

Basically what can you see? You can see that the trend seems to be very different between 3, 2 and 1. There are fewer points that have 
been distributed between 1 and 2 and a lot more points in region 3, that's first thing. And second of all, is the graph able to separate 
the clusters? Or the cluster points can be seen in different colours in different points. That is observable in the third region, that is, the other regions. 

These are some of the insights that you can gain here, right. However you get to see that cluster 7 includes all the regions. And similarly 
cluster 5 which is purple also includes all the regions. Whereas the cluster 2 seem to be only belonging to a few regions. 

Basically the cluster has done a good job on separating one cluster as one particular region alone, right. That is something that we can infer from this.

#Across Channel

Now the next step what we are going to do is basically we are going to again run the same plot but instead of region, we are going to take a look at the channel.

There are two channels that have been shown here, there is channel one and then there is channel 2. And channel 2 is a retail channel, whereas 
channel 1 refers to a channel via restaurants, cafes and so forth.

That can be shown as you can see here. These are the two channels, channel one and channel two.
And Horeca which has been shown here basically refers to hotel, restaurants or cafes.


```{r}
p+geom_point(aes(colour=as.factor(cluster)))+
  facet_grid(Channel~.)
```

Now let's look at this graph and see can we find any particular insight. Again, region 2, that is the retail channel seems to be showing a clear demarcation between different groups.

You can see that the cluster 7 is separated from the cluster 9, and it's further separated from say, cluster 4, right. And then a 
few blues which seem to be the high end of spending of milk and groceries.

Maybe the cluster 4 seem to be the mediocre range of spending of milk and grocery. However if you see in particular channel 1, 
all of the points are overlapping each other.

So you might not be able to get any clear insight out of this.

*.*

Now in the next step what we are going to do is that we're going to add another parameter called as the size parameter. The colour is 
going to be based on clusters but the size of a data point is going to vary based on a particular column.

In this case since we are trying to compare the two columns, milk and grocery, I am going to add another column called as fresh. Let's see how that varies across let's say, region.

First of all one thing that you see is there are some points which belong to a high end of spending of milk. And they also belong to 
high end of spending on groceries, customers are spending. And you also get to see that they seem to be spending.

#Analysis

```{r}
p+geom_point(aes(colour=as.factor(cluster),size=Fresh))+
  facet_grid(Region~.)
```

Let's take this particular point which seems to be larger in size. What does this mean? First of all it belongs to cluster 3. 
And again you see some more points here, which are all the blue if at all they seem to be there, they seem to be slightly big in size. 
This means that there are a couple of customers who spend a lot on milk, in this case. And they seem to be spending low on grocery; 
but they are spending high on the product 'fresh' as well. These customers will cater to customers who spend high on milk and fresh 
which spend low on groceries. That's what you can infer from this.

Similarly even though they spend low on milk and low on grocery, they still seem to be spending high on fresh - that's what this indicates. And slightly on the higher side.

Now if you come to this particular... And they belong to the region 3, or other region. If you come to the region 1, again you see that; 
there seems to be lower spending on milk and grocery, but very high spending on fresh. Obviously the insights that are shown here are a little limited, 
we don't see any particular trend and pattern. And if at all there is any cluster that seems to be spending very high on fresh, it seems to be the blue cluster. 
That is something you can infer.

*.*

Now instead of fresh, I wanted take a look at the size based on some other product, let's say, frozen. I want to see if this gives us better insights.

```{r}
p+geom_point(aes(colour=as.factor(cluster),size=Frozen))+
  facet_grid(Region~.)
```

Again, you can see that there are just one or two points that are very high in size, so it looks like either customers spend on just; 
a lot on 1 or 2 products and they tend to spend less on some other products. That could probably be the inference that you can get. 
Because here also, you get to see just 2 points that are large in size. Those customers who spend probably very low on grocery, 
a decently medium range on milk; seem to be spending most of their money probably on frozen products that you can see here. 
And they belong to cluster 3. So the clustering has done its procedure of actually finding out; these particular group of customers 
seem to be doing a better job in some other product.

*.*

Now instead of frozen, I'm going to actually run 'detergents_paper' and I'm going to see if maybe this is going to give any insight.

```{r}
p+geom_point(aes(colour=as.factor(cluster),size=Detergents_Paper))+
  facet_grid(Region~.) #You see some impact
```

This graph is definitely better than the rest of the graphs we have seen. First of all, I see some nice and new trends that seem to be 
showing here across given set of regions and also more number of bigger circles. Size seems to be high for many data points.

Why? Because it looks like most of the customers who spend a lot on milk and on grocery also seem to be spending a lot on detergents paper, 
not on any other product that we saw so far. And similarly even the cluster 8 and these basically belong to the green cluster; 
basically that particular cluster number you can see 5, basically belongs to high spending on milk, grocery and detergents paper.

Similarly you can see even the cluster number _ or maybe _ , which seem to be having the next high spending on detergents paper. 
And some belong to region 3 and you see some belong to region 2 and so forth. And as usual the region 3 is able to separate each 
of these clusters from each other; it's doing a better job compared to the other regions.

*.*

Now I have also tried to run based on the other product, delicassen. Let's just quickly see if this has any impact.

```{r}
p+geom_point(aes(colour=as.factor(cluster),size=Delicassen))+
  facet_grid(Region~.) 
```

This particular product also doesn't have much of an impact. You say that this just one big data point. Rest of the trends are actually similar to the other products.

*.*

You can say that may be one of the best insights we have got or the impact that we have seen seems to be definitely highest for using sizes, detergents paper.

Now what I'm going to do is I'm going to retain detergents paper as it is. And instead of just taking a look at region or only channel, I'm going to combine the two.

#Further Deep dive

```{r}
p+geom_point(aes(colour=as.factor(cluster),size=Detergents_Paper))+
  facet_grid(Region~Channel) #You see some impact
```

As you can see basically, you can see these particular rows, that is 1, 2 and 3So looks like everything that's been happening seems 
to be happening with the retail channel as opposed to this particular channel 1, where they're just very few data points and even 
if there are data points, they seem to be low spending on milk and grocery. And everything that's happening is happening on this particular channel 2.

You can see that there seems to be high spending on detergents paper as well, as well as high spending on milk and grocery here. 
But here it seems to be high spending on grocery and detergents paper and there seems to be a clear trend, at least there is a 
linear trend that you can observe. And based on which these clusters are divided.

Now the basic purpose of all these visualizations is that, yes you can obviously take a look at z-values, you can see whether 
your clusters make sense and so forth. But you can take a step forward and you could also try and plot this so that you have a better understanding.

There are a lot of factors in just one particular graph which might actually help me understand my clusters better. Maybe based on the z-values, 
let's see you have shortlisted clusters 4, 5 and 6 to be very different from the population, let's say.

Now you can, maybe using these visualizations, figure out what is it that makes these clusters a bit more unique? In this case, 
I can, maybe say that cluster 6 or cluster 7 seems to be unique because it seems to be speaking up not only for grocery and milk but also for detergents paper. 
Maybe that is something that the K-means cluster has analyzed and that's why it's put it into a particular unique group.

These are some of the kind of insights that you can actually come up using your cluster analysis. And also as I mentioned before, 
you can actually try running a more number of optimal clusters. If the optimal cluster that the graph that I showed you throws out 
to be 9, then maybe you can build K-means clustering with say, 8 and maybe 10. So plus or minus one, you can try a range and then 
you can pick out the best analysis that comes out from the 3.